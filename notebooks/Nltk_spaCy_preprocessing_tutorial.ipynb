{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brief nltk and spaCy Tutorial for text Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using both the nltk and spaCy libraries for data pre-processing, in our case, text cleaning tasks. \n",
    "\n",
    "## Documentation\n",
    "\n",
    "**nltk** : https://www.nltk.org/ \n",
    "\n",
    "**spaCy**: https://spacy.io/ \n",
    "\n",
    "## Installation \n",
    "\n",
    "**nltk**: https://www.nltk.org/install.html \n",
    "\n",
    "**spaCy**: https://spacy.io/usage/ \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports \n",
    "\n",
    "We start by importing the necessary packages. Make sure you download the nltk data, and also that you have download language model from spaCy. See \n",
    "\n",
    "**nltk**\n",
    "\n",
    "`nltk.download()` \n",
    "https://www.nltk.org/data.html\n",
    "\n",
    "**spacy**\n",
    "\n",
    "`python -m spacy download en_core_web_sm` `# small model` \n",
    "\n",
    "`python -m spacy download en_core_web_md   # medium model` \n",
    "\n",
    "`python -m spacy download en_core_web_lg # large model, we will be using this`\n",
    "\n",
    "https://spacy.io/usage/models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import spacy \n",
    "from nltk.corpus import stopwords # to filter stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk import sent_tokenize\n",
    "from nltk.stem import WordNetLemmatizer # lemmatizer \n",
    "from nltk.stem.snowball import SnowballStemmer # stemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "# nltk.download()# download nltk data , this will take a good while. \n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\") # large web model inizialization \n",
    "stopwords = set(stopwords.words('english')) # obtain english stopwords \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can have some sample text and see how to do common procedures. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example text \n",
    "text = \"\"\"Megathread: Bernie Sanders Undergoes Emergency Heart Procedure, Suspends Campaign Events Until Further Notice\n",
    "Megathread\n",
    "Sen. Bernie Sanders underwent heart surgery after he experienced chest discomfort during a campaign event on Tuesday, his campaign said.\n",
    "\n",
    "Jeff Weaver, a senior adviser to Sanders's campaign, said a medical evaluation of the Vermont senator discovered blockage in one of his arteries, and two stents were successfully inserted.\n",
    "\n",
    "Sen. Sanders is conversing and in good spirits, Weaver said. He will be resting up over the next few days. We are canceling his events and appearances until further notice, and we will continue to provide appropriate updates.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In what follows, both perform alright. However, we will be using mostly spaCy whenever possible. \n",
    "\n",
    "\n",
    "## nltk : tokenizing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Megathread', ':', 'Bernie', 'Sanders', 'Undergoes', 'Emergency', 'Heart', 'Procedure', ',', 'Suspends', 'Campaign', 'Events', 'Until', 'Further', 'Notice', 'Megathread', 'Sen.', 'Bernie', 'Sanders', 'underwent', 'heart', 'surgery', 'after', 'he', 'experienced', 'chest', 'discomfort', 'during', 'a', 'campaign', 'event', 'on', 'Tuesday', ',', 'his', 'campaign', 'said', '.', 'Jeff', 'Weaver', ',', 'a', 'senior', 'adviser', 'to', 'Sanders', \"'s\", 'campaign', ',', 'said', 'a', 'medical', 'evaluation', 'of', 'the', 'Vermont', 'senator', 'discovered', 'blockage', 'in', 'one', 'of', 'his', 'arteries', ',', 'and', 'two', 'stents', 'were', 'successfully', 'inserted', '.', 'Sen.', 'Sanders', 'is', 'conversing', 'and', 'in', 'good', 'spirits', ',', 'Weaver', 'said', '.', 'He', 'will', 'be', 'resting', 'up', 'over', 'the', 'next', 'few', 'days', '.', 'We', 'are', 'canceling', 'his', 'events', 'and', 'appearances', 'until', 'further', 'notice', ',', 'and', 'we', 'will', 'continue', 'to', 'provide', 'appropriate', 'updates', '.'] \n",
      "\n",
      "['Megathread: Bernie Sanders Undergoes Emergency Heart Procedure, Suspends Campaign Events Until Further Notice\\nMegathread\\nSen. Bernie Sanders underwent heart surgery after he experienced chest discomfort during a campaign event on Tuesday, his campaign said.', \"Jeff Weaver, a senior adviser to Sanders's campaign, said a medical evaluation of the Vermont senator discovered blockage in one of his arteries, and two stents were successfully inserted.\", 'Sen. Sanders is conversing and in good spirits, Weaver said.', 'He will be resting up over the next few days.', 'We are canceling his events and appearances until further notice, and we will continue to provide appropriate updates.'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "word_tokens = [token for token in word_tokenize(text, language='english')] # tokenize by words\n",
    "sent_tokens = [sent for sent in sent_tokenize(text, language='english')] # tokenize by sentence\n",
    "print(word_tokens, \"\\n\") \n",
    "print(sent_tokens, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## spacy : tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Megathread', 'Bernie', 'Sanders', 'Undergoes', 'Emergency', 'Heart', 'Procedure', 'Suspends', 'Campaign', 'Events', 'Until', 'Further', 'Notice', 'Megathread', 'Bernie', 'Sanders', 'underwent', 'heart', 'surgery', 'after', 'he', 'experienced', 'chest', 'discomfort', 'during', 'a', 'campaign', 'event', 'on', 'Tuesday', 'his', 'campaign', 'said', 'Jeff', 'Weaver', 'a', 'senior', 'adviser', 'to', 'Sanders', 'campaign', 'said', 'a', 'medical', 'evaluation', 'of', 'the', 'Vermont', 'senator', 'discovered', 'blockage', 'in', 'one', 'of', 'his', 'arteries', 'and', 'two', 'stents', 'were', 'successfully', 'inserted', 'Sanders', 'is', 'conversing', 'and', 'in', 'good', 'spirits', 'Weaver', 'said', 'He', 'will', 'be', 'resting', 'up', 'over', 'the', 'next', 'few', 'days', 'We', 'are', 'canceling', 'his', 'events', 'and', 'appearances', 'until', 'further', 'notice', 'and', 'we', 'will', 'continue', 'to', 'provide', 'appropriate', 'updates'] \n",
      "\n",
      "[Megathread: Bernie Sanders Undergoes Emergency Heart Procedure, Suspends Campaign Events, Until Further Notice\n",
      ", Megathread\n",
      ", Sen. Bernie Sanders underwent heart surgery after he experienced chest discomfort during a campaign event on Tuesday, his campaign said.\n",
      "\n",
      ", Jeff Weaver, a senior adviser to Sanders's campaign, said a medical evaluation of the Vermont senator discovered blockage in one of his arteries, and two stents were successfully inserted.\n",
      "\n",
      ", Sen. Sanders is conversing and in good spirits, Weaver said., He will be resting up over the next few days., We are canceling his events and appearances until further notice, and we will continue to provide appropriate updates.] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(text) # process text with the model \n",
    "\n",
    "sp_word_tokens = [token.text for token in doc if token.text.isalpha()]\n",
    "sp_sent_tokens = [sent for sent in doc.sents]\n",
    "print(sp_word_tokens, \"\\n\")\n",
    "print(sp_sent_tokens, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stemming (nltk) \n",
    "\n",
    "\n",
    "Basic idea: chop the word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['megathread', ':', 'berni', 'sander', 'undergo', 'emerg', 'heart', 'procedur', ',', 'suspend', 'campaign', 'event', 'until', 'further', 'notic', 'megathread', 'sen.', 'berni', 'sander', 'underw', 'heart', 'surgeri', 'after', 'he', 'experienc', 'chest', 'discomfort', 'dure', 'a', 'campaign', 'event', 'on', 'tuesday', ',', 'his', 'campaign', 'said', '.', 'jeff', 'weaver', ',', 'a', 'senior', 'advis', 'to', 'sander', \"'s\", 'campaign', ',', 'said', 'a', 'medic', 'evalu', 'of', 'the', 'vermont', 'senat', 'discov', 'blockag', 'in', 'one', 'of', 'his', 'arteri', ',', 'and', 'two', 'stent', 'were', 'success', 'insert', '.', 'sen.', 'sander', 'is', 'convers', 'and', 'in', 'good', 'spirit', ',', 'weaver', 'said', '.', 'he', 'will', 'be', 'rest', 'up', 'over', 'the', 'next', 'few', 'day', '.', 'we', 'are', 'cancel', 'his', 'event', 'and', 'appear', 'until', 'further', 'notic', ',', 'and', 'we', 'will', 'continu', 'to', 'provid', 'appropri', 'updat', '.']\n"
     ]
    }
   ],
   "source": [
    "stemmer = SnowballStemmer(language='english')  # stemmer algorithm \n",
    "stemmer.stem(\"Cats\") # example \n",
    "\n",
    "stemmed = [stemmer.stem(word) for word in word_tokens]  # the whole text \n",
    "print(stemmed) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stemming (spaCy) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Megathread', 'Bernie', 'Sanders', 'Undergoes', 'Emergency', 'Heart', 'Procedure', 'Suspends', 'Campaign', 'Events', 'Until', 'Further', 'Notice', 'Megathread', 'Bernie', 'Sanders', 'underwent', 'heart', 'surgery', 'after', 'he', 'experienced', 'chest', 'discomfort', 'during', 'a', 'campaign', 'event', 'on', 'Tuesday', 'his', 'campaign', 'said', 'Jeff', 'Weaver', 'a', 'senior', 'adviser', 'to', 'Sanders', 'campaign', 'said', 'a', 'medical', 'evaluation', 'of', 'the', 'Vermont', 'senator', 'discovered', 'blockage', 'in', 'one', 'of', 'his', 'arteries', 'and', 'two', 'stents', 'were', 'successfully', 'inserted', 'Sanders', 'is', 'conversing', 'and', 'in', 'good', 'spirits', 'Weaver', 'said', 'He', 'will', 'be', 'resting', 'up', 'over', 'the', 'next', 'few', 'days', 'We', 'are', 'canceling', 'his', 'events', 'and', 'appearances', 'until', 'further', 'notice', 'and', 'we', 'will', 'continue', 'to', 'provide', 'appropriate', 'updates'] \n",
      "\n",
      "[Megathread: Bernie Sanders Undergoes Emergency Heart Procedure, Suspends Campaign Events, Until Further Notice\n",
      ", Megathread\n",
      ", Sen. Bernie Sanders underwent heart surgery after he experienced chest discomfort during a campaign event on Tuesday, his campaign said.\n",
      "\n",
      ", Jeff Weaver, a senior adviser to Sanders's campaign, said a medical evaluation of the Vermont senator discovered blockage in one of his arteries, and two stents were successfully inserted.\n",
      "\n",
      ", Sen. Sanders is conversing and in good spirits, Weaver said., He will be resting up over the next few days., We are canceling his events and appearances until further notice, and we will continue to provide appropriate updates.] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(text) # process the text with the model \n",
    "\n",
    "sp_word_tokens = [token.text for token in doc if token.text.isalpha()] # process every token \n",
    "sp_sent_tokens = [sent for sent in doc.sents]\n",
    "print(sp_word_tokens, \"\\n\")\n",
    "print(sp_sent_tokens, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lemmatization (nltk) \n",
    "\n",
    "Bring the word back to its dictionary form "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['megathread', ':', 'berni', 'sander', 'undergo', 'emerg', 'heart', 'procedur', ',', 'suspend', 'campaign', 'event', 'until', 'further', 'notic', 'megathread', 'sen.', 'berni', 'sander', 'underw', 'heart', 'surgeri', 'after', 'he', 'experienc', 'chest', 'discomfort', 'dure', 'a', 'campaign', 'event', 'on', 'tuesday', ',', 'his', 'campaign', 'said', '.', 'jeff', 'weaver', ',', 'a', 'senior', 'advis', 'to', 'sander', \"'s\", 'campaign', ',', 'said', 'a', 'medic', 'evalu', 'of', 'the', 'vermont', 'senat', 'discov', 'blockag', 'in', 'one', 'of', 'his', 'arteri', ',', 'and', 'two', 'stent', 'were', 'success', 'insert', '.', 'sen.', 'sander', 'is', 'convers', 'and', 'in', 'good', 'spirit', ',', 'weaver', 'said', '.', 'he', 'will', 'be', 'rest', 'up', 'over', 'the', 'next', 'few', 'day', '.', 'we', 'are', 'cancel', 'his', 'event', 'and', 'appear', 'until', 'further', 'notic', ',', 'and', 'we', 'will', 'continu', 'to', 'provid', 'appropri', 'updat', '.']\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer() # instantiate nltk lemmatizer \n",
    "\n",
    "# lemmatize all tokens \n",
    "lemm_tokens_nltk = [stemmer.stem(token) for token in word_tokens] \n",
    "print(lemm_tokens_nltk)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lemmatization (spacy)\n",
    "Better than nltk, specially for other languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Megathread', 'megathread'), ('Bernie', 'Bernie'), ('Sanders', 'Sanders'), ('Undergoes', 'undergo'), ('Emergency', 'Emergency'), ('Heart', 'Heart'), ('Procedure', 'Procedure'), ('Suspends', 'suspend'), ('Campaign', 'campaign'), ('Events', 'event'), ('Until', 'until'), ('Further', 'further'), ('Notice', 'notice'), ('Megathread', 'Megathread'), ('Bernie', 'Bernie'), ('Sanders', 'Sanders'), ('underwent', 'undergo'), ('heart', 'heart'), ('surgery', 'surgery'), ('after', 'after'), ('he', '-PRON-'), ('experienced', 'experience'), ('chest', 'chest'), ('discomfort', 'discomfort'), ('during', 'during'), ('a', 'a'), ('campaign', 'campaign'), ('event', 'event'), ('on', 'on'), ('Tuesday', 'Tuesday'), ('his', '-PRON-'), ('campaign', 'campaign'), ('said', 'say'), ('Jeff', 'Jeff'), ('Weaver', 'Weaver'), ('a', 'a'), ('senior', 'senior'), ('adviser', 'adviser'), ('to', 'to'), ('Sanders', 'Sanders'), ('campaign', 'campaign'), ('said', 'say'), ('a', 'a'), ('medical', 'medical'), ('evaluation', 'evaluation'), ('of', 'of'), ('the', 'the'), ('Vermont', 'Vermont'), ('senator', 'senator'), ('discovered', 'discover'), ('blockage', 'blockage'), ('in', 'in'), ('one', 'one'), ('of', 'of'), ('his', '-PRON-'), ('arteries', 'artery'), ('and', 'and'), ('two', 'two'), ('stents', 'stent'), ('were', 'be'), ('successfully', 'successfully'), ('inserted', 'insert'), ('Sanders', 'Sanders'), ('is', 'be'), ('conversing', 'converse'), ('and', 'and'), ('in', 'in'), ('good', 'good'), ('spirits', 'spirit'), ('Weaver', 'Weaver'), ('said', 'say'), ('He', '-PRON-'), ('will', 'will'), ('be', 'be'), ('resting', 'rest'), ('up', 'up'), ('over', 'over'), ('the', 'the'), ('next', 'next'), ('few', 'few'), ('days', 'day'), ('We', '-PRON-'), ('are', 'be'), ('canceling', 'cancel'), ('his', '-PRON-'), ('events', 'event'), ('and', 'and'), ('appearances', 'appearance'), ('until', 'until'), ('further', 'further'), ('notice', 'notice'), ('and', 'and'), ('we', '-PRON-'), ('will', 'will'), ('continue', 'continue'), ('to', 'to'), ('provide', 'provide'), ('appropriate', 'appropriate'), ('updates', 'update')]\n",
      "Lemma:  megathread\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(text) # fit text to model \n",
    "doc_lemmas = [(token.text, token.lemma_) for token in doc if token.text.isalpha()]\n",
    "print(doc_lemmas)\n",
    "\n",
    "print(\"Lemma: \", doc_lemmas[0][1]) # how to access lemmas "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocessing-function template using nltk  and re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = word_tokenize # tokenizes\n",
    "stemmer = SnowballStemmer(language='english')  # stemmer\n",
    "lemmatizer = WordNetLemmatizer() # lemmatizer \n",
    "\n",
    "def preprocess_text(sentence, stem=False, lemmatize=False): \n",
    "    \"\"\"\n",
    "    Cleans text list by applying the following steps: \n",
    "        1. Tokenize the input sentence \n",
    "        2. Remove punctuation, symbols and unwanted characters\n",
    "        3. Convert the tokens to lowercase \n",
    "        4. Stem or lemmatize (according to input)\n",
    "        5. Remove stopwords and empty strings\n",
    "    \"\"\"\n",
    "    # Tokenize\n",
    "    tokens = tokenizer(sentence) \n",
    "    \n",
    "    # Remove punctuation & symbols\n",
    "    tokens = [re.sub(r\"[^a-zA-Z]\",\"\", token) for token in tokens ]\n",
    "    \n",
    "    # convert to lowercase \n",
    "    tokens = [token.lower() for token in tokens]\n",
    "    \n",
    "    # Stem or lemmatize\n",
    "    if stem: \n",
    "        tokens = [stemmer.stem(token) for token in tokens] \n",
    "    if lemmatize:\n",
    "        tokens = [lemmatizer.lemmatize(token) for token in tokens] \n",
    "    \n",
    "    # remove stopwords and empty strings \n",
    "    tokens = [token for token in tokens if token not in stopwords\n",
    "              and len(token) > 1] \n",
    "    \n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Note we can change the stemmer and lemmatizer for spaCy's ones instead. \n",
    "\n",
    "# example \n",
    "ex1_stem = preprocess_text(text, stem='true')\n",
    "ex2_lemm = preprocess_text(text, lemmatize='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "megathread berni sander undergo emerg heart procedur suspend campaign event notic megathread sen berni sander underw heart surgeri experienc chest discomfort dure campaign event tuesday campaign said jeff weaver senior advis sander campaign said medic evalu vermont senat discov blockag one arteri two stent success insert sen sander convers good spirit weaver said rest next day cancel event appear notic continu provid appropri updat\n"
     ]
    }
   ],
   "source": [
    "print(ex1_stem) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "megathread bernie sander undergoes emergency heart procedure suspends campaign event notice megathread sen bernie sander underwent heart surgery experienced chest discomfort campaign event tuesday campaign said jeff weaver senior adviser sander campaign said medical evaluation vermont senator discovered blockage one artery two stent successfully inserted sen sander conversing good spirit weaver said resting next day canceling event appearance notice continue provide appropriate update\n"
     ]
    }
   ],
   "source": [
    "print(ex2_lemm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe carefully the differences in stemming vs lemmatizing  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
